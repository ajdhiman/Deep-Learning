{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN0oJPp669XX5ULbNMr6mF3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajdhiman/Deep-Learning/blob/main/DL_Classification_Model_(Cat_%26_Dog).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H43Yl6W8ZVNn"
      },
      "outputs": [],
      "source": [
        "import urllib.request as request\n",
        "from zipfile import ZipFile\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import tensorflow  as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading Data"
      ],
      "metadata": {
        "id": "U29zaAeTbTYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "remoteSourcePath = \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\"\n",
        "localZipFilePath = \"data.zip\"\n",
        "localPath = \"Data\"\n",
        "localPathForClasses= \"Data/PetImages\""
      ],
      "metadata": {
        "id": "bqR6BG3aaBpY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename, headers = request.urlretrieve(url=remoteSourcePath, filename=localZipFilePath)"
      ],
      "metadata": {
        "id": "Y1QviQDkcY_w"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_updated_list_of_files(list_of_files):\n",
        "        return [f for f in list_of_files if f.endswith(\".jpg\") and (\"Cat\" in f or \"Dog\" in f)]\n",
        "\n",
        "def preProcess(zf: ZipFile, f: str, working_dir: str):\n",
        "\n",
        "    target_filepath = os.path.join(working_dir, f)\n",
        "    if not os.path.exists(target_filepath):\n",
        "        zf.extract(f, working_dir)\n",
        "\n",
        "    if os.path.getsize(target_filepath) == 0:\n",
        "            os.remove(target_filepath)"
      ],
      "metadata": {
        "id": "hsLrqPhIbzK8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with ZipFile(file=localZipFilePath, mode=\"r\") as zf:\n",
        "  list_of_files = zf.namelist()\n",
        "  updated_list_of_files = get_updated_list_of_files(list_of_files)\n",
        "\n",
        "  print(len(updated_list_of_files))\n",
        "  for f in tqdm(updated_list_of_files):\n",
        "      preProcess(zf, f, localPath)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdNr5dP-awDb",
        "outputId": "987a8181-cbbd-41f2-bf7d-ad436b4f620d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25000/25000 [00:10<00:00, 2362.15it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting VGG16 Model"
      ],
      "metadata": {
        "id": "63MdLoPvfvDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.applications.vgg16.VGG16(\n",
        "            input_shape=[224, 224, 3],\n",
        "            weights=\"imagenet\",\n",
        "            include_top=False\n",
        "        )\n",
        "\n",
        "model.save(\"VGG16.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCNwS3aIcgGL",
        "outputId": "53e183a7-4225-4f5b-9d3d-d9cbe8bfb833"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_full_model(model, classes, freeze_all, freeze_till, learning_rate):\n",
        "        if freeze_all:\n",
        "            model.trainable = False\n",
        "        elif (freeze_till is not None) and (freeze_till > 0):\n",
        "            for layer in model.layers[:-freeze_till]:\n",
        "                layer.trainable = False\n",
        "\n",
        "        flatten_in = tf.keras.layers.Flatten()(model.output)\n",
        "        prediction = tf.keras.layers.Dense(\n",
        "            units=classes,\n",
        "            activation=\"softmax\"\n",
        "        )(flatten_in)\n",
        "\n",
        "        full_model = tf.keras.models.Model(\n",
        "            inputs=model.input,\n",
        "            outputs=prediction\n",
        "        )\n",
        "\n",
        "        full_model.compile(\n",
        "            optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
        "            loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "            metrics=[\"accuracy\"]\n",
        "        )\n",
        "\n",
        "        full_model.summary()\n",
        "        return full_model"
      ],
      "metadata": {
        "id": "4Y1jSpBMiCTl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fullModel = prepare_full_model(model, 2, True, None, 0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8XNgWAPitEm",
        "outputId": "483402ce-b3c9-483c-b663-b4c303ef7bc4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 50178     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,764,866\n",
            "Trainable params: 50,178\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_valid_generator():\n",
        "\n",
        "        dataGenerator_kwargs = dict(\n",
        "            rescale = 1./255,\n",
        "            validation_split=0.20\n",
        "        )\n",
        "\n",
        "        dataflow_kwargs = dict(\n",
        "            target_size=[224, 224],\n",
        "            batch_size=16,\n",
        "            interpolation=\"bilinear\"\n",
        "        )\n",
        "\n",
        "        valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "            **dataGenerator_kwargs\n",
        "        )\n",
        "\n",
        "        valid_generator = valid_datagenerator.flow_from_directory(\n",
        "            directory=localPathForClasses,\n",
        "            subset=\"validation\",\n",
        "            shuffle=False,\n",
        "            **dataflow_kwargs\n",
        "        )\n",
        "\n",
        "\n",
        "        train_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "            rotation_range=40,\n",
        "            horizontal_flip=True,\n",
        "            width_shift_range=0.2,\n",
        "            height_shift_range=0.2,\n",
        "            shear_range=0.2,\n",
        "            zoom_range=0.2,\n",
        "            **dataGenerator_kwargs\n",
        "        )\n",
        "\n",
        "        train_generator = train_datagenerator.flow_from_directory(\n",
        "            directory=localPathForClasses,\n",
        "            subset=\"training\",\n",
        "            shuffle=True,\n",
        "            **dataflow_kwargs\n",
        "        )\n",
        "\n",
        "        return train_generator,valid_generator\n",
        "\n",
        "train_generator,valid_generator = train_valid_generator()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZrlH2FdjR1z",
        "outputId": "8606c23b-62c2-48e9-93b0-fdd8a890ec42"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4998 images belonging to 2 classes.\n",
            "Found 20000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator,valid_generator = train_valid_generator()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rT1kAnOQm0Ge",
        "outputId": "e773fda0-47c4-4368-9a5a-954a5fab37d9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4998 images belonging to 2 classes.\n",
            "Found 20000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
        "validation_steps = valid_generator.samples // valid_generator.batch_size\n",
        "\n",
        "fullModel.fit(\n",
        "    train_generator,\n",
        "    epochs=1,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_steps=validation_steps,\n",
        "    validation_data=valid_generator\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaU0sd13n9_O",
        "outputId": "af3365b1-2843-4a0b-9934-5fa905534ec3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  27/1250 [..............................] - ETA: 5:02 - loss: 13.0155 - accuracy: 0.5579"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/TiffImagePlugin.py:858: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1250/1250 [==============================] - 350s 271ms/step - loss: 6.2497 - accuracy: 0.6865 - val_loss: 1.0625 - val_accuracy: 0.8998\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7c4a7ff48d00>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fullModel.save(\"DLClassification.h5\")"
      ],
      "metadata": {
        "id": "lyV8PizkovD1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _valid_generator():\n",
        "\n",
        "  datagenerator_kwargs = dict(\n",
        "    rescale = 1./255,\n",
        "    validation_split=0.30\n",
        "  )\n",
        "\n",
        "  dataflow_kwargs = dict(\n",
        "    target_size=[224,224],\n",
        "    batch_size=16,\n",
        "    interpolation=\"bilinear\"\n",
        "  )\n",
        "\n",
        "  valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    **datagenerator_kwargs\n",
        "  )\n",
        "\n",
        "  valid_generator = valid_datagenerator.flow_from_directory(\n",
        "    directory=localPathForClasses,\n",
        "    subset=\"validation\",\n",
        "    shuffle=True,\n",
        "    **dataflow_kwargs\n",
        "  )\n",
        "  return  valid_generator\n"
      ],
      "metadata": {
        "id": "grfv8cFPuDt6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_generator= _valid_generator()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQnG7KFou7Xx",
        "outputId": "ecf74e0e-89bf-47f2-c7b1-28ef0ab5766c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7498 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fullModel.evaluate(valid_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDJf3HO4vLhe",
        "outputId": "f1c7a329-79c4-40b0-c90d-336d54413d8b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "469/469 [==============================] - 38s 82ms/step - loss: 1.0337 - accuracy: 0.8992\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0336908102035522, 0.8991731405258179]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vKU7nMnVwDGk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}